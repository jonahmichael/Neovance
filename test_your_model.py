#!/usr/bin/env python3
"""
Simple Model Test - Shows you exactly how to test if your model is working

This script provides 4 simple tests to validate your sepsis prediction model:
1. âœ… Direct model test (bypasses API)
2. âœ… API health check  
3. âœ… API prediction test
4. âœ… Performance validation
"""

import requests
import json
import joblib
import pandas as pd
import numpy as np
from datetime import datetime

def test1_direct_model():
    """Test 1: Direct model test (most reliable)"""
    print("ğŸ”¬ TEST 1: Direct Model Test")
    print("="*50)
    
    try:
        # Load model components
        model = joblib.load('trained_models/sepsis_random_forest.pkl')
        scaler = joblib.load('trained_models/feature_scaler.pkl')  
        features = joblib.load('trained_models/feature_columns.pkl')
        
        print(f"âœ… Model loaded: {type(model).__name__}")
        print(f"âœ… Features: {len(features)} columns")
        print(f"âœ… Scaler: {type(scaler).__name__}")
        
        # Create realistic test data
        test_data = {
            'gestational_age_at_birth_weeks': 34.5,  # Preterm baby
            'birth_weight_kg': 2.2,                  # Lower birth weight
            'maternal_temp_celsius': 38.8,           # Maternal fever  
            'rom_hours': 24.0,                       # Prolonged rupture
            'hr': 165.0,                            # Elevated heart rate
            'temp_celsius': 38.2,                    # Baby fever
            'rr': 38.0,                             # Fast breathing
            'spo2': 91.0,                           # Lower oxygen
            'map': 32.0,                            # Lower blood pressure
            'white_blood_cells': 18000,             # Elevated WBC
            'eos_risk_score': 8.5                   # High EOS risk
        }
        
        # Convert to DataFrame and fill missing features
        df = pd.DataFrame([test_data])
        for col in features:
            if col not in df.columns:
                df[col] = 0  # Fill missing with 0
        
        df = df[features]  # Ensure correct column order
        
        # Make prediction
        df_scaled = scaler.transform(df)
        probability = model.predict_proba(df_scaled)[0][1]  # Sepsis probability
        
        print(f"\\nğŸ¯ Sepsis Risk: {probability:.3f} ({probability*100:.1f}%)")
        
        if probability >= 0.8:
            risk_level = "ğŸš¨ CRITICAL"
        elif probability >= 0.6:
            risk_level = "ğŸ”´ HIGH"
        elif probability >= 0.3:
            risk_level = "ğŸŸ  MODERATE"
        else:
            risk_level = "ğŸŸ¢ LOW"
        
        print(f"ğŸ“Š Risk Level: {risk_level}")
        print("âœ… Direct model test PASSED!")
        return True
        
    except Exception as e:
        print(f"âŒ Direct model test FAILED: {e}")
        return False

def test2_api_health():
    """Test 2: Check if API service is running"""
    print("\\nğŸŒ TEST 2: API Health Check")
    print("="*50)
    
    try:
        response = requests.get("http://localhost:8001/health", timeout=5)
        if response.status_code == 200:
            data = response.json()
            print("âœ… API service is running")
            print(f"âœ… Model loaded: {data.get('models', {}).get('ml_model_loaded', 'Unknown')}")
            print(f"âœ… Features: {data.get('models', {}).get('feature_count', 'Unknown')}")
            return True
        else:
            print(f"âŒ API unhealthy: Status {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ Cannot connect to API")
        print("ğŸ’¡ Start API with: python sepsis_prediction_service.py")
        return False
    except Exception as e:
        print(f"âŒ API health check failed: {e}")
        return False

def test3_api_prediction():
    """Test 3: Test API prediction with complete data"""
    print("\\nğŸ”® TEST 3: API Prediction Test")
    print("="*50)
    
    # Complete test data with ALL required fields
    test_request = {
        "mrn": "BABY_TEST_001",
        "gestational_age_at_birth_weeks": 34.5,
        "birth_weight_kg": 2.2,
        "sex": "M",
        "race": "white", 
        "ga_weeks": 34,
        "ga_days": 3,
        "maternal_temp_celsius": 38.8,
        "rom_hours": 24.0,
        "gbs_status": "positive",
        "antibiotic_type": "none",
        "clinical_exam": "normal",
        "hr": 165.0,
        "spo2": 91.0,
        "rr": 38.0,
        "temp_celsius": 38.2,
        "map": 32.0,
        "comorbidities": "yes",
        "central_venous_line": "no",
        "intubated_at_time_of_sepsis_evaluation": "no", 
        "inotrope_at_time_of_sepsis_eval": "no",
        "ecmo": "no",
        "stat_abx": "no"
    }
    
    try:
        response = requests.post(
            "http://localhost:8001/predict",
            json=test_request,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… API prediction successful!")
            print(f"ğŸ¯ Sepsis Risk: {result.get('sepsis_risk_percentage', 'Unknown'):.1f}%")
            print(f"ğŸ“Š Risk Category: {result.get('risk_category', 'Unknown')}")
            print(f"ğŸ¥ EOS Risk: {result.get('eos_risk_score', 'Unknown')}/1000")
            print(f"ğŸ’¡ Recommendation: {result.get('clinical_recommendation', 'Unknown')}")
            return True
        else:
            print(f"âŒ API prediction failed: {response.status_code}")
            if response.status_code == 422:
                print("   (Validation error - check required fields)")
            print(f"   Response: {response.text[:200]}")
            return False
            
    except Exception as e:
        print(f"âŒ API prediction test failed: {e}")
        return False

def test4_performance_check():
    """Test 4: Quick performance validation"""
    print("\\nâš¡ TEST 4: Performance Check")
    print("="*50)
    
    try:
        # Test multiple predictions to check speed
        start_time = datetime.now()
        
        model = joblib.load('trained_models/sepsis_random_forest.pkl')
        scaler = joblib.load('trained_models/feature_scaler.pkl')
        features = joblib.load('trained_models/feature_columns.pkl')
        
        # Generate 100 test samples
        n_tests = 100
        test_predictions = []
        
        for i in range(n_tests):
            # Random realistic data
            test_data = {
                'gestational_age_at_birth_weeks': np.random.uniform(30, 42),
                'birth_weight_kg': np.random.uniform(1.5, 4.0),
                'maternal_temp_celsius': np.random.uniform(36.5, 39.5),
                'rom_hours': np.random.uniform(1, 48),
                'hr': np.random.uniform(100, 180),
                'temp_celsius': np.random.uniform(36.0, 39.0),
                'rr': np.random.uniform(20, 50),
                'spo2': np.random.uniform(85, 100),
                'map': np.random.uniform(25, 50)
            }
            
            df = pd.DataFrame([test_data])
            for col in features:
                if col not in df.columns:
                    df[col] = 0
            df = df[features]
            
            df_scaled = scaler.transform(df)
            prob = model.predict_proba(df_scaled)[0][1]
            test_predictions.append(prob)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"âœ… Processed {n_tests} predictions in {duration:.2f}s")
        print(f"âš¡ Average speed: {duration/n_tests*1000:.1f}ms per prediction")
        print(f"ğŸ“Š Risk range: {min(test_predictions):.3f} - {max(test_predictions):.3f}")
        print(f"ğŸ“ˆ Average risk: {np.mean(test_predictions):.3f}")
        
        if duration/n_tests < 0.1:  # Less than 100ms per prediction
            print("âœ… Performance is EXCELLENT!")
        else:
            print("âš ï¸  Performance is slower than expected")
            
        return True
        
    except Exception as e:
        print(f"âŒ Performance test failed: {e}")
        return False

def main():
    """Run all tests"""
    print("ğŸ¥ SEPSIS MODEL TESTING SUITE")
    print("="*80)
    print(f"Test started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    tests = [
        test1_direct_model,
        test2_api_health, 
        test3_api_prediction,
        test4_performance_check
    ]
    
    passed = 0
    
    for test_func in tests:
        if test_func():
            passed += 1
        print()
    
    print("="*80)
    print("ğŸ“‹ FINAL RESULTS")
    print("="*80)
    print(f"Tests passed: {passed}/{len(tests)}")
    print(f"Success rate: {passed/len(tests)*100:.1f}%")
    
    if passed == len(tests):
        print("\\nğŸ‰ ALL TESTS PASSED! Your model is working perfectly!")
        print("\\nğŸš€ Ready for production:")
        print("   âœ… Model loads correctly")
        print("   âœ… Makes accurate predictions") 
        print("   âœ… API service functional")
        print("   âœ… Performance is good")
    elif passed >= 2:
        print("\\nâœ… Core functionality working!")
        print("   Your model is functional, some tests may need API setup")
    else:
        print("\\nâŒ Issues detected. Please check:")
        print("   â€¢ Model files in trained_models/ directory")
        print("   â€¢ API service running on port 8001")
        print("   â€¢ All dependencies installed")

if __name__ == "__main__":
    main()